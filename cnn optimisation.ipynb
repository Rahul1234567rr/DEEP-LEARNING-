{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6f8884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import img_to_array,array_to_img\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence \n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b29c80fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc590966",
   "metadata": {},
   "source": [
    "# fashion_mnist "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20f154",
   "metadata": {},
   "source": [
    "### Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n",
    "\n",
    "Zalando seeks to replace the original MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d842235",
   "metadata": {},
   "source": [
    "### Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n",
    "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c6abc",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "0 T-shirt/top\n",
    "\n",
    "1 Trouser\n",
    "\n",
    "2 Pullover\n",
    "\n",
    "3 Dress\n",
    "\n",
    "4 Coat\n",
    "\n",
    "5 Sandal\n",
    "\n",
    "6 Shirt\n",
    "\n",
    "7 Sneaker\n",
    "\n",
    "8 Bag\n",
    "\n",
    "9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f28cb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd7e70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f24ab991",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)=ds.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f4481df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b52a84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255.0\n",
    "test_images=test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fcfa0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.reshape(len(train_images),28,28,1)\n",
    "test_images=test_images.reshape(len(test_images),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b72aacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931828c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "af132845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_model(hp):\n",
    "    model=keras.Sequential([keras.layers.Conv2D(filters=hp.Int('conv_1_filter',min_value=32,max_value=128,step=16),\n",
    "                                                kernel_size=hp.Choice('conv_1_kernel',values=[3,5]),\n",
    "                                                activation='relu',\n",
    "                                                input_shape=(28,28,1)),\n",
    "                            keras.layers.Conv2D(filters=hp.Int('conv_1_filter',min_value=32,max_value=128,step=16),\n",
    "                                                kernel_size=hp.Choice('conv_2_kernel',values=[3,5]),\n",
    "                                                activation='relu'),\n",
    "                            keras.layers.Flatten(),\n",
    "                            keras.layers.Dense(units=hp.Int(\"units\", min_value=32, max_value=512, step=32), \n",
    "                                               activation=\"relu\"),\n",
    "                            keras.layers.Dense(10,activation='softmax')\n",
    "                           ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-2,1e-3,1e-4])),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "                             \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4624a703",
   "metadata": {},
   "outputs": [],
   "source": [
    " from kerastuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "93cf8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(bulid_model,objective='val_accuracy',max_trials=5,directory='output',project_name='mnist fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801d893",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035e274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 45m 47s]\n",
      "val_accuracy: 0.8491666913032532\n",
      "\n",
      "Best val_accuracy So Far: 0.9096666574478149\n",
      "Total elapsed time: 01h 06m 41s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "96                |64                |conv_1_filter\n",
      "3                 |5                 |conv_1_kernel\n",
      "3                 |5                 |conv_2_kernel\n",
      "64                |96                |units\n",
      "0.0001            |0.001             |learning_rate\n",
      "\n",
      "Epoch 1/3\n",
      " 750/1688 [============>.................] - ETA: 1:22 - loss: 0.5740 - accuracy: 0.7970"
     ]
    }
   ],
   "source": [
    "  tuner_search.search(train_images,train_labels,epochs=3,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599efd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
